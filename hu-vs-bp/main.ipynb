{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentos Invariantes de Hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hu_moments(image, quadrants=(1,1)):\n",
    "    # Tamanho dos quadrantes\n",
    "    width, height = image.shape[0], image.shape[1]\n",
    "    part_width = width // quadrants[0]\n",
    "    part_height = height // quadrants[1]\n",
    "    \n",
    "    # Calculate\n",
    "    huMoments = list()\n",
    "    for i in range(quadrants[0]):\n",
    "        for j in range(quadrants[1]):\n",
    "            #coordenadas da parte da imagem\n",
    "            left = i * part_width\n",
    "            upper = j * part_height\n",
    "            right = left + part_width\n",
    "            lower = upper + part_height\n",
    "\n",
    "            # Retorna o quadrante da imagem\n",
    "            quad = image[left:right, upper:lower]\n",
    "\n",
    "            # Calculate Moments \n",
    "            moments = cv2.moments(quad)\n",
    "            # Calculate Hu Moments\n",
    "            huMoments.extend(cv2.HuMoments(moments).flatten())\n",
    "            \n",
    "    return huMoments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_pixels(image, quadrants=(1,1)):\n",
    "    # Tamanho dos quadrantes\n",
    "    width, height = image.shape[0], image.shape[1]\n",
    "    part_width = width // quadrants[0]\n",
    "    part_height = height // quadrants[1]\n",
    "\n",
    "    counts = []\n",
    "    for i in range(quadrants[0]):\n",
    "        for j in range(quadrants[1]):\n",
    "            #coordenadas da parte da imagem\n",
    "            left = i * part_width\n",
    "            upper = j * part_height\n",
    "            right = left + part_width\n",
    "            lower = upper + part_height\n",
    "\n",
    "            # Retorna o quadrante da imagem\n",
    "            part = image[left:right, upper:lower]\n",
    "\n",
    "            # Contar os pixels pretos (assumindo que menores que 128 são pretos)\n",
    "            black_pixels = np.sum(np.array(part) < 128)\n",
    "\n",
    "            # Adicionar a contagem à lista\n",
    "            counts.append(black_pixels)\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(caminho_p):\n",
    "    file_dict = {}\n",
    "    for pasta in Path(caminho_p).iterdir():\n",
    "        if pasta.is_dir():\n",
    "            file_dict[pasta.name] = []\n",
    "            \n",
    "            for file in Path(pasta).iterdir():\n",
    "                if file.is_file() and (file.name.endswith(\".png\") or file.name.endswith(\".jpg\")):\n",
    "                    file_dict[pasta.name].append(file)\n",
    "    return file_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 175) (4000, 25) (4000,)\n"
     ]
    }
   ],
   "source": [
    "database = get_files('../fourShapes/')\n",
    "\n",
    "quadrantes = (2,2)\n",
    "X_hu, X_bp, y = list(), list(), list()\n",
    "\n",
    "for classe in database:\n",
    "    for item in database[classe]:        \n",
    "        image = cv2.imread(str(item), cv2.IMREAD_GRAYSCALE) #open img\n",
    "\n",
    "        #hu\n",
    "        X_hu.append(hu_moments(image, quadrantes))\n",
    "        X_bp.append(black_pixels(image, quadrantes))\n",
    "        y.append(classe)\n",
    "\n",
    "X_hu, X_bp, y = np.array(X_hu), np.array(X_bp), np.array(y)\n",
    "print(X_hu.shape, X_bp.shape, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU: Conjunto de treino (X, y) e teste (X, y): (2400, 175) (2400,) (1600, 175) (1600,)\n",
      "BP: Conjunto de treino (X, y) e teste (X, y): (2400, 25) (2400,) (1600, 25) (1600,)\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "X_hu = StandardScaler().fit_transform(X_hu)\n",
    "X_bp = StandardScaler().fit_transform(X_bp)\n",
    "\n",
    "# separa em conjunto de treino e teste\n",
    "X_hu_train, X_hu_test, y_hu_train, y_hu_test = train_test_split(X_hu, y, test_size=0.4)\n",
    "X_bp_train, X_bp_test, y_bp_train, y_bp_test = train_test_split(X_bp, y, test_size=0.4)\n",
    "\n",
    "print('HU: Conjunto de treino (X, y) e teste (X, y):', X_hu_train.shape, y_hu_train.shape, X_hu_test.shape, y_hu_test.shape)\n",
    "print('BP: Conjunto de treino (X, y) e teste (X, y):', X_bp_train.shape, y_bp_train.shape, X_bp_test.shape, y_bp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hu Moments:\n",
      "accuracy: 0.958125\n",
      "\n",
      "Black Pixels:\n",
      "accuracy: 0.993125\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "neighbors = 3\n",
    "\n",
    "#momentos de hu\n",
    "knn_hu = KNeighborsClassifier(n_neighbors=neighbors, metric='euclidean')\n",
    "knn_hu.fit(X_hu_train, y_hu_train)\n",
    "y_hu_pred = knn_hu.predict(X_hu_test)\n",
    "\n",
    "print('Hu Moments:')\n",
    "print('accuracy:', accuracy_score(y_hu_test, y_hu_pred))\n",
    "# print(confusion_matrix(y_hu_test, y_hu_pred))\n",
    "# print(classification_report(y_hu_test, y_hu_pred, labels=knn_hu.classes_))\n",
    "print()\n",
    "\n",
    "#black pixels\n",
    "knn_bp = KNeighborsClassifier(n_neighbors=neighbors, metric='euclidean')\n",
    "knn_bp.fit(X_bp_train, y_bp_train)\n",
    "y_bp_pred = knn_bp.predict(X_bp_test)\n",
    "\n",
    "print('Black Pixels:')\n",
    "print('accuracy:', accuracy_score(y_bp_test, y_bp_pred))\n",
    "# print(confusion_matrix(y_bp_test, y_bp_pred))\n",
    "# print(classification_report(y_bp_test, y_bp_pred, labels=knn_bp.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
